#!/usr/bin/env python
# PopPairPSMC 0.0.1
# Generated by dx-app-wizard.
#
# Parallelized execution pattern: Your app will generate multiple jobs
# to perform some computation in parallel, followed by a final
# "postprocess" stage that will perform any additional computations as
# necessary.
#
# See http://wiki.dnanexus.com/Developer-Portal for documentation and
# tutorials on how to modify this file.
#
# DNAnexus Python Bindings (dxpy) documentation:
#   http://autodoc.dnanexus.com/bindings/python/current/

import os
import dxpy

@dxpy.entry_point("postprocess")
def postprocess(input2):
    # Change the following to process whatever input this stage
    # receives.  You may also want to copy and paste the logic to download
    # and upload files here as well if this stage receives file input
    # and/or makes file output.

#    for output in process_outputs:
#    pass
    print input2
    return { "answer": "placeholder value" }

@dxpy.entry_point("process")
def process(input1):
    # Change the following to process whatever input this stage
    # receives.  You may also want to copy and paste the logic to download
    # and upload files here as well if this stage receives file input
    # and/or makes file output.
    psmc20_id = 'project-B53fX06gYqYbb6B87kgQ0007' #dxpy.find_one_project(more_ok=False, name="PSMC_20")['id']
    applets = {}
    for applet in dxpy.find_data_objects(name='PSMC', name_mode='regexp', project=psmc20_id, return_handler=True):
        name = applet.describe()['name']
        applets[name] = applet
    print applets['PSMCFa_Conv_20'].describe()
    dxjob1 = applets['PSMCFa_Conv_20'].run(applet_input=input1, project=psmc20_id, folder='/psmcfa')
    
    return { "output": "placeholder value" }

@dxpy.entry_point("main")
def main(pop1, pop2):
    # Split your work into parallel tasks.  As an example, the
    # following generates 10 subjobs running with the same dummy
    # input.
    psmc20_id = 'project-B53fX06gYqYbb6B87kgQ0007' #Dxpy.find_one_project(zero_ok=True, more_ok=False, name="PSMC_20")['id']
    print psmc20_id, dxpy.WORKSPACE_ID
    applets = {}
    for applet in dxpy.find_data_objects(name='PSMC', name_mode='regexp', project=psmc20_id, return_handler=True):
        name = applet.describe()['name']
        applets[name] = applet
    files1 = {}
    for result in dxpy.find_data_objects(name=pop1, name_mode='regexp', classname='file', project=psmc20_id):
        id = result['id']
        name = dxpy.describe(id)['name']
        files1[name] = id
    files2 = {}
    if (pop1 != pop2):
        for result in dxpy.find_data_objects(name=pop2, name_mode='regexp', classname='file', project=psmc20_id):
            id = result['id']
            name = dxpy.describe(id)['name']
            files2[name] = id
    if len(files2) == 0 and pop1 != pop2:
        return {}
    app1jobs = []
    if len(files2) == 0:
        #Single population processing
        subjobs = []
        fn1sort = files1.keys()
        fn1sort.sort()
        for i in range(1):#len(fn1sort)):
            for j in range(1, 2):#len(fn1sort)):
                outname = pop1+'.'+str(i+1)+'.'+pop1+str(j+1)+'.psmcfa'
                applet_in = { "file1": dxpy.dxlink(files1[fn1sort[i]]), "file2": dxpy.dxlink(files1[fn1sort[j]]), "skip":20, "outname":outname }
                aj = applets['PSMCFa_Conv_20'].run(applet_input=applet_in, project=psmc20_id, folder='/psmcfa')
                app1jobs.append(aj)
    elif len(files2) > 0:
        subjobs = []
        fn1sort = files1.keys()
        fn2sort = files2.keys()
        fn1sort.sort()
        fn2sort.sort()
        for i in range(len(fn1sort)):
            for j in range(len(fn2sort)):
                outname = pop1+'.'+str(i+1)+'.'+pop2+str(j+1)+'.psmcfa'
                applet_in = { "file1": files1[fn1sort[i+1]], "file2": files2[fn2sort[j]], "skip":20, "outname":outname }
                aj = applets['PSMCFa_Conv_20'].run(applet_input=applet_in, project=psmc20_id, folder='/psmcfa')
                app1jobs.append(aj)
    # The following line creates the job that will perform the
    # "postprocess" step of your app.  We've given it an input field
    # that is a list of job-based object references created from the
    # "process" jobs we just created.  Assuming those jobs have an
    # output field called "output", these values will be passed to the
    # "postprocess" job.  Because these values are not ready until the
    # "process" jobs finish, the "postprocess" job WILL NOT RUN until
    # all job-based object references have been resolved (i.e. the
    # jobs they reference have finished running).
    #
    # If you do not plan to have the "process" jobs create output that
    # the "postprocess" job will require, then you can explicitly list
    # the dependencies to wait for those jobs to finish by setting the
    # "depends_on" field to the list of subjobs to wait for (it
    # accepts either dxpy handlers or string IDs in the list).  We've
    # included this parameter in the line below as well for
    # completeness, though it is unnecessary if you are providing
    # job-based object references in the input that refer to the same
    # set of jobs.

#    postprocess_job = dxpy.new_dxjob(fn_input={"input2":2}, fn_name="postprocess", depends_on=subjobs)

    # If you would like to include any of the output fields from the
    # postprocess_job as the output of your app, you should return it
    # here using a job-based object reference.  If the output field in
    # the postprocess function is called "answer", you can pass that
    # on here as follows:
    #
    # return { "app_output_field": postprocess_job.get_output_ref("answer"), ...}
    #
    # Tip: you can include in your output at this point any open
    # objects (such as gtables) which will be closed by a job that
    # finishes later.  The system will check to make sure that the
    # output object is closed and will attempt to clone it out as
    # output into the parent container only after all subjobs have
    # finished.

    output = {}

    return output

dxpy.run()
